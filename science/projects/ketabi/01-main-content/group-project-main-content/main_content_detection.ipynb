{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meFTi41DYb2y"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdDFF6WRuSaQ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import base64\n",
        "import requests\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from scipy.stats import zscore\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHnFmYjNrbr8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjY6h384K36N"
      },
      "source": [
        "# Download and prepare data\n",
        "\n",
        "\n",
        "because I use google colab to run my code\n",
        "first of all I download my data from google drive\n",
        "this data was uploaded manualy on google drive and\n",
        "are publicly available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGc_Y5uorv2_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!gdown 1_iQKcOhqtCPrta3Cz0pjbO02C2VaQ4wV -O data.rar\n",
        "!unrar x \"/content/data.rar\" \"/content/main_content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVhVC3HEHbM3"
      },
      "source": [
        "# LXML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tILagJ4jLEyj",
        "outputId": "b3d13883-2bf1-4ee3-fb1e-6cb74aac5471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selectolax\n",
            "  Downloading selectolax-0.3.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.23 in /usr/local/lib/python3.10/dist-packages (from selectolax) (0.29.34)\n",
            "Installing collected packages: selectolax\n",
            "Successfully installed selectolax-0.3.13\n"
          ]
        }
      ],
      "source": [
        "! pip install selectolax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8dYs6NKMP7T"
      },
      "outputs": [],
      "source": [
        "def read_batch(path):\n",
        "\n",
        "        html64file = pd.read_csv(path, nrows=10)\n",
        "        htmls_encoded = html64file['html'].to_list()\n",
        "\n",
        "\n",
        "        return htmls_encoded\n",
        "\n",
        "html_encoded = read_batch('/content/main_content/isna_all.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2howDd6Mqwt",
        "outputId": "cf183103-5c80-417d-8473-fa136f94df1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 of 10 were read successfuly!\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "import base64\n",
        "from selectolax.parser import HTMLParser\n",
        "from lxml import html \n",
        "import pandas as pd \n",
        "\n",
        "option = 'selectolax'\n",
        "parsed_pages = []\n",
        "for encoded_html in html_encoded:\n",
        "    unicode_html = base64.b64decode(encoded_html)\n",
        "    try:\n",
        "        if option == 'lxlm': \n",
        "            parsed_html = html.fromstring(unicode_html)\n",
        "            body_text = parsed_html.body.text\n",
        "    \n",
        "        elif option == 'selectolax': \n",
        "            parsed_html = HTMLParser(unicode_html, use_meta_tags=True)\n",
        "            body_text = parsed_html.body.text()\n",
        "\n",
        "        if body_text.startswith('402 '):\n",
        "            pass\n",
        "        elif body_text.startswith('403 '):\n",
        "            pass\n",
        "        elif body_text.startswith('404 '):\n",
        "            pass \n",
        "        else: \n",
        "            parsed_pages.append(parsed_html)\n",
        "    except:\n",
        "        print(\"--------\")\n",
        "print(len(parsed_pages), 'of', len(html_encoded), \n",
        "            'were read successfuly!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQNLO4ynN-wD",
        "outputId": "12363d06-20b9-45ef-ff7d-04735b6cf6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node text: ذخیره نفت سفید در صورت قطعی گاز کافی است\n",
            "1\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'class': 'first-title', 'itemprop': 'headline'}\n",
            "tag: h1\n",
            "node text: رئیس شرکت ملی پخش فرآورده‌های نفتی ناحیه اردستان گفت: در صورت قطع گازِ مشترکان خانگی تمهیدات لازم برای ذخیره نفت سفید برای شهرستان اردستان اندیشیده شده است.\n",
            "2\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'class': 'summary', 'itemprop': 'description'}\n",
            "tag: p\n",
            "node text: حمیدرضا فروزنده در گفت‌وگو با ایسنا، اظهار کرد: با وضعیتی که پیش آمده شرایط بحرانی را در بحث سوخت گاز طبیعی در کشور شاهد هستیم که باعث افزایش مصرف سوخت مایع در کشور شده است.\n",
            "3\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: وی افزود: صنایع و نیروگاه‌های برق که در ماه‌های گذشته با گاز طبیعی فعالیت می‌کردند، اکنون با سوخت مایع در حال فعالیت هستند، همچنین محدودیت‌هایی در خدمت رسانی جایگاه‌های سوخت «سی. اِن. جی» به وجود آمده که باعث افزایش مصرف سوخت‌های مایع شده است.\n",
            "4\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: رئیس شرکت ملی پخش فرآورده‌های نفتی ناحیه اردستان با بیان اینکه در شرایط کنونی که تامین گاز با چالش و مشکل روبرو شده است و احتمال قطعی گاز مشترکان خانگی وجود دارد تمهیدات لازم برای ذخیره نفت سفید برای شهرستان اندیشیده شده است، گفت: در شهرستان دو نمایندگی فروش نفت سفید وجود دارد که موجودی انبار این واحدها تکمیل است و در صورت لزوم مورد استفاده قرار می‌گیرد.\n",
            "5\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: فروزنده در خصوص تامین سوخت صنایع کوچکی که به دلیل محدودیت‌ها، گاز آنها قطع می‌شود، گفت: معمولا سوخت صنایع کوچک، گاز طبیعی است و هنوز پیش بینی لازمی برای جایگزینی سوخت صنایع کوچک شهرستان انجام نشده است.\n",
            "6\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: وی درباره کمبود گازوئیل در جایگاه‌های سوخت شهرستان، گفت: با توجه به محدودیت‌هایی که در موضوع سوخت صنایع به وجود آمده و تاکید دولت براولویت تامین سوخت نیروگاه‌های برق، طبیعتا تراز تولید و مصرف گازوئیل در کشور دچار اختلال می‌شود و مجبور هستیم مصرف جایگاه‌های سوخت را کاهش دهیم.\n",
            "7\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: رئیس شرکت ملی پخش فرآورده‌های نفتی ناحیه اردستان با بیان اینکه اکنون به طور روزانه در جایگاه‌های سوخت شهرستان اردستان ۵۴۰ متر مکعب گازوئیل و ۸۰ متر مکعب بنزین عرضه می‌شود، گفت: با توجه به موقعیت جغرافیایی شهرستان اردستان و عبور محور ترانزیت شمال به جنوب کشور و خدمات با کیفیتی که جایگاه‌های بین راهی به رانندگان ماشین‌های سنگین می‌دهند فروش گازوئیل در این شهرستان قابل توجه است.\n",
            "8\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: فروزنده خاطرنشان کرد: برخی از مصرف کنندگانی که فاقد خدمات گاز طبیعی هستند، اعم از اصناف واحدهای تجاری و کسبه سیار و ... می‌توانند با ثبت نام در سامانه سدف و طی کردن فرایند ثبت نام و دریافت تاییدیه مورد نیاز کپسول گاز مایع خود را دریافت کنند.\n",
            "9\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: انتهای پیام\n",
            "10\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'style': 'text-align:justify'}\n",
            "tag: p\n",
            "node text: شما در حال پاسخ به نظر «» هستید.\n",
            "11\n",
            "node.parent  div\n",
            "---------------------\n",
            "attributes: {'class': 'alert alert-info hide fade'}\n",
            "tag: div\n"
          ]
        }
      ],
      "source": [
        "\n",
        "i = 0\n",
        "for node in parsed_pages[5].body.traverse(include_text = True):\n",
        "    text = node.text(deep=False, separator='', strip=True)\n",
        "    if node.tag in ['h1', 'p', 'div'] and len(text) > 0:\n",
        "        print('node text: %s' % node.text(deep=False, separator='', strip=True))\n",
        "        i += 1\n",
        "        # if node.text(deep=False, separator='', strip=True) == description:\n",
        "        print(i)\n",
        "        print(\"node.parent \", node.parent.tag)\n",
        "        print('---------------------')\n",
        "        print('attributes: %s' % node.attributes)\n",
        "        print('tag: %s' % node.tag)\n",
        "        # print('parent tag: %s' % node.parent.tag)\n",
        "    if i > 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8RE9It-8IqZi"
      },
      "outputs": [],
      "source": [
        "from typing import *\n",
        "import numpy as np \n",
        "\n",
        "class Features():\n",
        "    '''\n",
        "    #FIXME: implement functions to extract feature vector from a parsed page \n",
        "    '''\n",
        "\n",
        "\n",
        "    def __init__(self, html_object, n_negative_sample = 100): \n",
        "        self.html_object = html_object\n",
        "        self.og_desc_text = self.find_og_desc_text(html_object)\n",
        "        self.n_negative_sample = n_negative_sample\n",
        "        self.desired_tags = ['h1', 'p', 'div']\n",
        "        self.tag_index = {'div' : 0, 'p': 1, 'h1':2}\n",
        "        pass\n",
        "\n",
        "    def get_feature_vectors(self, ) -> Tuple[np.ndarray, List[np.bool8]]: \n",
        "        '''\n",
        "        return a tuple containing the feature vectors alongside of their correspounding labels\n",
        "        '''\n",
        "        features = []\n",
        "        labels = []\n",
        "        count = 0\n",
        "\n",
        "        for leaf in self.html_object.body.traverse(include_text=True): \n",
        "            text = leaf.text(deep=False, separator='', strip=True)\n",
        "            if leaf.tag in self.desired_tags and len(text) > 0:\n",
        "                count += 1\n",
        "\n",
        "                features.append(self.get_feature_leaf(leaf))\n",
        "                labels.append(self.check_label(leaf))\n",
        "            \n",
        "            if count >= self.n_negative_sample : \n",
        "                break\n",
        "\n",
        "        return [features, labels]\n",
        "\n",
        "    def check_label(self, node : object) -> bool:\n",
        "        if self._is_description_node(node):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def find_og_desc_text(self, page : object) -> str:\n",
        "        head = page.css_first('meta[property=\"og:description\"]')\n",
        "        if head is None:\n",
        "            return None\n",
        "\n",
        "        og_description = head.attributes.get('content')\n",
        "        if og_description is None:\n",
        "            return None\n",
        "        return og_description\n",
        "\n",
        "\n",
        "    def _is_description_node(self, node):\n",
        "        return True if node.text(deep=False, separator='', strip=True) == self.og_desc_text else 0\n",
        "\n",
        "\n",
        "\n",
        "    def get_feature_leaf(self, node_lxml_object) -> np.ndarray: \n",
        "        present_nodes = self._get_present_tags(node_lxml_object)\n",
        "        lenght = self._extract_text_lengh(node_lxml_object)\n",
        "        depth = self._extract_depth(node_lxml_object)\n",
        "        word_count = self._extract_word_count(node_lxml_object)\n",
        "\n",
        "        return [lenght, depth, word_count]\n",
        "\n",
        "\n",
        "\n",
        "    def _get_present_tags(self, node) -> np.ndarray:\n",
        "        '''\n",
        "        returns the present tags of a specefic node as a fixed-size binary array\n",
        "        ex: [p, div, h1, ...] -> [1, 0, 2, 0, 0, ...]\n",
        "        '''\n",
        "\n",
        "        parent_tag = node.parent.tag\n",
        "        #TODO\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "    def _extract_depth(self, node: object) -> int:\n",
        "        \"\"\"Write a function to extract the text_lenght inside the lxml_object\n",
        "        Args:\n",
        "            lxml_object: a lxml object for each node, children involved\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "    def _extract_text_lengh(self, node: object) -> int:\n",
        "        \"\"\"Write a function to extract the text_lenght inside the lxml_object\n",
        "        Args:\n",
        "            lxml_object: Dictionary of line data for the coverage file.\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        return len(node.text(deep=False, separator='', strip=True))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _extract_word_count(self, node: object) -> int:\n",
        "        \"\"\"Write a function to extract the text_lenght inside the lxml_object\n",
        "        Args:\n",
        "            node: Dictionary of line data for the coverage file.\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        return len(list(node.text(deep=False, separator='', strip=True).split()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "b-RCFZND1yBD"
      },
      "outputs": [],
      "source": [
        "extractor = Features(parsed_pages[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lcb1M2RE2V6A",
        "outputId": "578258aa-19a3-49a3-ed74-4d1e5b974486"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'رئیس شرکت ملی پخش فرآورده\\u200cهای نفتی ناحیه اردستان گفت: در صورت قطع گازِ مشترکان خانگی تمهیدات لازم برای ذخیره نفت سفید برای شهرستان اردستان اندیشیده شده است.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extractor.og_desc_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_EDaqf984Xzv"
      },
      "outputs": [],
      "source": [
        "f = extractor.get_feature_vectors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfmSpx2N5F0m",
        "outputId": "05d49907-eca5-4ea4-ede3-72b3219929d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[[40, 0, 9],\n",
              "  [156, 0, 27],\n",
              "  [173, 0, 35],\n",
              "  [243, 0, 44],\n",
              "  [356, 0, 68],\n",
              "  [201, 0, 37],\n",
              "  [275, 0, 49],\n",
              "  [378, 0, 68],\n",
              "  [241, 0, 48],\n",
              "  [11, 0, 2],\n",
              "  [32, 0, 8],\n",
              "  [39, 0, 9],\n",
              "  [25, 0, 4]],\n",
              " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRwUb0Qr9w-8"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqp3ZDUDnxZI"
      },
      "source": [
        "## Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l80r77ch9x-c"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix_(test_labels, predicted_labels, version):\n",
        "    if not os.path.exists('result'):\n",
        "        os.makedirs('result')\n",
        "\n",
        "    print(\"\\nconfusion_matrix\\n\")\n",
        "    cm = confusion_matrix(test_labels, predicted_labels)\n",
        "    plt.subplots(figsize=(10, 6))\n",
        "    sn.heatmap(cm, annot = True, fmt = 'd', cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.savefig(f'confusion_matrix_{version}.png', bbox_inches='tight')\n",
        "\n",
        "def model_result(y_test,y_pred, version):\n",
        "    ra_score = roc_auc_score(y_test,y_pred)\n",
        "    a_score = accuracy_score(y_test,y_pred)\n",
        "    p_score = precision_score(y_test,y_pred)\n",
        "    r_score = recall_score(y_test,y_pred)\n",
        "    f1 = f1_score(y_test,y_pred)\n",
        "    \n",
        "    print('roc_auc_score : ',ra_score)\n",
        "    print('accuracy_score: ',a_score)\n",
        "    print('precision_score: ',p_score)\n",
        "    print('recall_score: ',r_score)\n",
        "    print('f1-score :', f1)\n",
        "    print('confusion_matrix: ',confusion_matrix(y_test,y_pred))\n",
        "    confusion_matrix_(y_test,y_pred, version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTGn1cK6oI5V"
      },
      "source": [
        "## ML Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLQY53ybpBov"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ndlNKfoAio9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "def extra_tree_train(x_train, x_test, y_train, y_test):\n",
        "    clf = ExtraTreesClassifier(n_estimators=10, criterion='entropy')\n",
        "    #Train the model using the training sets\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test.fillna(0))\n",
        "    model_result(y_test,y_pred, version='ExtraTreesClassifier_entropy')\n",
        "\n",
        "\n",
        "\n",
        "def random_forest_classifier(x_train, x_test, y_train, y_test):\n",
        "    random_forest_clf = RandomForestClassifier(max_depth=20)\n",
        "    #Train the model using the training sets\n",
        "    random_forest_clf.fit(x_train, y_train)\n",
        "    y_pred = random_forest_clf.predict(x_test.fillna(0))\n",
        "    model_result(y_test,y_pred, version='RandomForestClassifier')\n",
        "\n",
        "\n",
        "\n",
        "def catboost_classifier(x_train, x_test, y_train, y_test):\n",
        "    # initializing the model\n",
        "    cbc = CatBoostClassifier(iterations=100, max_depth=16)\n",
        "\n",
        "    # training the model\n",
        "    cbc.fit(x_train, y_train)\n",
        "    y_pred = cbc.predict(x_test)\n",
        "    model_result(y_test,y_pred, version='CatBoostClassifier')\n",
        "\n",
        "\n",
        "def xgboost_classifier(x_train, x_test, y_train, y_test):\n",
        "    xgb_cl = xgb.XGBClassifier()\n",
        "    xgb_cl.fit(x_train, y_train)\n",
        "    y_pred = xgb_cl.predict(x_test)\n",
        "    model_result(y_test,y_pred, version='XGBClassifier')\n",
        "    print(xgb_cl.feature_importances_)\n",
        "    return xgb_cl\n",
        "\n",
        "def SVM_classifier(x_train, x_test, y_train, y_test):\n",
        "    # define outlier detection model\n",
        "    weight = class_weight.compute_class_weight\\\n",
        "    (class_weight ='balanced', classes = np.unique(y_train), y = y_train)\n",
        "    weights = {i : weight[i] for i in range(2)}\n",
        "\n",
        "    svm_model = SVC(class_weight = weights)\n",
        "    svm_model.fit(x_train, y_train)\n",
        "    y_pred = svm_model.predict(x_test)\n",
        "    model_result(y_test,y_pred, version='SVMClassifier')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
